{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b72bbff",
   "metadata": {},
   "source": [
    "# Analyse du trafic cycliste à Paris en fonction de la météo\n",
    "\n",
    "Ce mini-projet d'extraction et d'analyse de données autour du trafic cycliste à Paris a pour objectif :\n",
    "- Comprendre et appliquer le concept d'ETL (Extract, Trasnform, Load)\n",
    "- Explorer des données ouvertes (open data)\n",
    "- Croiser deux sources de données (API + scraping)\n",
    "- Stocker les données dans une base SQL (SQLite3)\n",
    "- Réaliser une visualisation (Streamlit) et/ou un modèle simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e7456c",
   "metadata": {},
   "source": [
    "Précisions quant au concept d'ETL :\n",
    "- **Extract**: récupérer des données depuis une source (API, fichier, web...)\n",
    "- **Transform**: nettoyer, reformater, enrichir les données\n",
    "- **Load**: stocker les données dans une format structuré (CSV, DB, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71a4918",
   "metadata": {},
   "source": [
    "On souhaite répondre à la problématique suivante :\n",
    "\n",
    "**Comment la météo influence-t-elle l'utilisation des pistes cyclables à Paris ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186130a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d50e8f0",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6a24a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import  datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a91909",
   "metadata": {},
   "source": [
    "## Extraction des données\n",
    "Sources :\n",
    "\n",
    "- [Données météo station Tour Eiffel](https://www.meteociel.fr/climatologie/obs_villes.php)\n",
    "- [Données compteurs de vélos pour le site de comptage nommé 36 quai de Grenelle](https://opendata.paris.fr/explore/dataset/comptage-velo-donnees-compteurs/api/?disjunctive.id_compteur&disjunctive.nom_compteur&disjunctive.id&disjunctive.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77271ce9",
   "metadata": {},
   "source": [
    "### Scraping Meteociel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df264bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeteocielProcessor:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://www.meteociel.fr/climatologie/obs_villes.php?code2=75107005\"\n",
    "    \n",
    "    def get_daily_data_from_period(self, start_month:int, start_year:int, end_month:int, end_year:int):\n",
    "        # Init on start date\n",
    "        current_date = datetime.date(year=start_year, month=start_month, day=1)\n",
    "        end_date = datetime.date(year=end_year, month=end_month, day=1)\n",
    "        try:\n",
    "            df = self.get_daily_data_from_date(current_date.month, current_date.year)\n",
    "        except:\n",
    "            df = pd.DataFrame()\n",
    "            \n",
    "        # Loop until end date is reached\n",
    "        while current_date < end_date:\n",
    "            current_date = current_date + relativedelta(months=1)\n",
    "            try:\n",
    "                df = pd.concat([df, self.get_daily_data_from_date(current_date.month, current_date.year)], axis=0)\n",
    "            except:\n",
    "                print(f\"Failed to load data from {current_date.month}-{current_date.year}\")\n",
    "        return df\n",
    "    \n",
    "    def get_daily_data_from_date(self, month:int, year:int):\n",
    "        page = self.fetch_page_from_date(month, year)\n",
    "        df = self.get_daily_data_from_page(page, month, year)\n",
    "        return df\n",
    "    \n",
    "    def fetch_page_from_date(self, month:int, year:int):\n",
    "        \"\"\"\n",
    "        Fetch the content of the the meteociel website for station 'Eiffel Tower' for a given month & year.as_integer_ratio\n",
    "\n",
    "        :\n",
    "        \"\"\"\n",
    "        # Error handling\n",
    "        if month not in [i for i in range(1,13)]:\n",
    "            raise ValueError(f\"Month must be an `int` from 1 to 12, was given {month} instead.\")\n",
    "        if year not in [i for i in range(1996, 2026)]:\n",
    "            raise ValueError(f\"Year must be an ``int from 1996 to 2025, was given {year} instead.\")\n",
    "        \n",
    "        # Fetch data\n",
    "        url = f\"{self.base_url}&mois={month}&annee={year}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            #print(f\"Content from {month}-{year} successfully fetched.\")\n",
    "            return BeautifulSoup(response.content, \"html.parser\")\n",
    "        else:\n",
    "            print(f\"Failed to load content from {month}-{year}.\")\n",
    "            print(response.text)\n",
    "    \n",
    "    def get_daily_data_from_page(self, page, month:int, year:int):\n",
    "        data = {\"date\": [],\n",
    "        \"temp_max\": [],\n",
    "        \"temp_min\": []\n",
    "        }\n",
    "\n",
    "        # Retrieve dates\n",
    "        dates_content = (\n",
    "            page\n",
    "            .find_all(\"table\", cellpadding=\"2\")[0]\n",
    "            .find_all(\"td\", bgcolor=\"#FFFFCC\")\n",
    "            )\n",
    "        for el in dates_content:\n",
    "            data[\"date\"].append(f\"{el.text.split(\" \")[-1]}-{month}-{year}\")\n",
    "\n",
    "        # Retrieve max temp\n",
    "        maxtemp_content = (\n",
    "            page\n",
    "            .find_all(\"table\", cellpadding=\"2\")[0]\n",
    "            .find_all(\"td\", bgcolor=\"#FFDDDD\")\n",
    "        )\n",
    "        for el in maxtemp_content:\n",
    "            temp = el.text.split()[0]\n",
    "            if temp == \"---\":\n",
    "                temp = None\n",
    "            else:\n",
    "                temp = float(temp)\n",
    "            data[\"temp_max\"].append(temp)\n",
    "\n",
    "        # Retrieve min temp\n",
    "        mintemp_content = (\n",
    "            page\n",
    "            .find_all(\"table\", cellpadding=\"2\")[0]\n",
    "            .find_all(\"td\", bgcolor=\"#DDDDFF\")\n",
    "        )\n",
    "        for el in mintemp_content:\n",
    "            temp = el.text.split()[0]\n",
    "            if temp == \"---\":\n",
    "                temp = None\n",
    "            else:\n",
    "                temp = float(temp)\n",
    "            data[\"temp_min\"].append(temp)\n",
    "        \n",
    "        # Transform to dataframe and return\n",
    "        df = pd.DataFrame(data)\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%d-%m-%Y\")\n",
    "        df = df.set_index(keys=\"date\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = meteociel_processor.fetch_page_from_date(2, 2024)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c98b796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load data from 2-2024\n",
      "Failed to load data from 3-2024\n",
      "Failed to load data from 4-2024\n",
      "Failed to load data from 5-2024\n",
      "Failed to load data from 6-2024\n",
      "Failed to load data from 7-2024\n",
      "Failed to load data from 8-2024\n",
      "Failed to load data from 9-2024\n",
      "Failed to load data from 10-2024\n",
      "Failed to load data from 11-2024\n",
      "Failed to load data from 12-2024\n",
      "Failed to load data from 1-2025\n",
      "Failed to load data from 2-2025\n",
      "Failed to load data from 3-2025\n",
      "Failed to load data from 4-2025\n",
      "Failed to load data from 5-2025\n",
      "Failed to load data from 6-2025\n",
      "Failed to load data from 7-2025\n",
      "Failed to load data from 8-2025\n",
      "Failed to load data from 9-2025\n",
      "Failed to load data from 10-2025\n",
      "Failed to load data from 11-2025\n",
      "Failed to load data from 12-2025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteociel_processor = MeteocielProcessor()\n",
    "start_date = datetime.date(year=2024, month=1, day=1)\n",
    "end_date = datetime.date(year=2025, month=12, day=1)\n",
    "\n",
    "df = meteociel_processor.get_daily_data_from_period(start_date.month, start_date.year, end_date.month, end_date.year)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ce750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meteociel.to_csv(\"../data/daily-temperatures-2024-2025.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18ad69",
   "metadata": {},
   "source": [
    "### API Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1c1fea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def update_cyclist_data(data, offset):\n",
    "    url = \"https://opendata.paris.fr/api/explore/v2.1/catalog/datasets/comptage-velo-donnees-compteurs/records\"\n",
    "    params = {\n",
    "        \"select\": [\"sum_counts\",\"date\"],\n",
    "        \"limit\": 100,\n",
    "        \"offset\": offset,\n",
    "        \"refine\": ['nom_compteur:36 quai de Grenelle NE-SO']\n",
    "        }\n",
    "    response = json.loads(\n",
    "        requests.get(url, params).content\n",
    "        )\n",
    "    \n",
    "    data[\"date\"] = data[\"date\"] + [dic['date'] for dic in response[\"results\"]]\n",
    "    data[\"sum_count\"] = data[\"sum_count\"] + [dic['sum_counts'] for dic in response[\"results\"]]\n",
    "\n",
    "def get_total_count():\n",
    "    url = \"https://opendata.paris.fr/api/explore/v2.1/catalog/datasets/comptage-velo-donnees-compteurs/records\"\n",
    "    offset = 0\n",
    "    params = {\n",
    "        \"select\": [\"sum_counts\",\"date\"],\n",
    "        \"limit\": 0,\n",
    "        \"offset\": offset,\n",
    "        \"refine\": ['nom_compteur:36 quai de Grenelle NE-SO']\n",
    "        }\n",
    "    response = json.loads(\n",
    "        requests.get(url, params).content\n",
    "        )\n",
    "    return response['total_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dcb20da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"date\": [],\n",
    "    \"sum_count\": []\n",
    "    }\n",
    "offset = 0\n",
    "while offset <= get_total_count():\n",
    "    update_cyclist_data(data, offset)\n",
    "    offset += 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cabb1132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyclist = pd.DataFrame(data)\n",
    "df_cyclist[\"date\"] = pd.to_datetime(df_cyclist[\"date\"])\n",
    "df_cyclist = df_cyclist.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0357ba",
   "metadata": {},
   "source": [
    "## Transformation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaddf3e",
   "metadata": {},
   "source": [
    "Les données de comptage de vélo sont échantillonnées toutes les heures, là où les données de températures sont quotidiennes.\n",
    "- Nous commençons donc par récupérer le compte journalier de vélo avec un `groupby().sum()`\n",
    "- Avant de pouvoir `join` les deux tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "45042b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-01</th>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-02</th>\n",
       "      <td>1601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-03</th>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-04</th>\n",
       "      <td>2947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-05</th>\n",
       "      <td>3125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sum_count\n",
       "2024-11-01       1389\n",
       "2024-11-02       1601\n",
       "2024-11-03       1409\n",
       "2024-11-04       2947\n",
       "2024-11-05       3125"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cyclist = df_cyclist.groupby(df_cyclist.index.date).sum()\n",
    "df_cyclist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6a3c11ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_meteociel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[130]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = df_cyclist.join(\u001b[43mdf_meteociel\u001b[49m, how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m df.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'df_meteociel' is not defined"
     ]
    }
   ],
   "source": [
    "df = df_cyclist.join(df_meteociel, how='left')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
